{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb687ac",
   "metadata": {},
   "source": [
    "## First stage.\n",
    "\n",
    "Let's install the PySpark package on the local environment. Before using the pip instal pyspark command, you should check for preinstalled Java/OpenJDK packages at least version 11 and Python3.6+. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841dfb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/katyanekrasova/opt/anaconda3/lib/python3.9/site-packages (3.3.0)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /Users/katyanekrasova/opt/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c7c2e",
   "metadata": {},
   "source": [
    "Great! Import the sparkSession element from the pyspark.sql library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b2d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b313b",
   "metadata": {},
   "source": [
    "By using the SparkSession command and passing it to the Spark variable, we denote the \"entry point\" for the local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbb3dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/19 15:11:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# use SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed7c49",
   "metadata": {},
   "source": [
    "If a test run detects an error: *22/10/18 20:37:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable*. You will need to use form .setLogLevel(). That will change the logs WARN and start the spark session as much as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbac81d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/19 15:11:13 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# set appName and master\n",
    "\n",
    "appName = \"Spark - Setting Log Level\"\n",
    "master = \"local\"\n",
    "\n",
    "# create Spark session\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# use spark setLogLevel()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1fcc3c",
   "metadata": {},
   "source": [
    "By redefining the entry point, we eliminate log WARN. But only to use SparkSession. I'll update the project later where I'll look at using the SQL language to communicate with Spark.\n",
    "\n",
    "Lets testing our spark version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d831e52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25dd65",
   "metadata": {},
   "source": [
    "\n",
    "Let's begin. Let's download the dataframe found at <code>[Kaggle][1] \n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/anujsingh098/top-1000-imdb-movies        \"Kaggle\"\n",
    "</code>\n",
    "\n",
    "I really like movies and the movie industry, so we are going to use the IMDb Top 1000 Movies dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198d79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920fa8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://air-ekaterina:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x120eb28e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run Spark\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef596440",
   "metadata": {},
   "source": [
    "Let's find our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25ad98b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poster_Link,Series_Title,Released_Year,Certificate,Runtime,Genre,IMDB_Rating,Overview,Meta_score,Director,Star1,Star2,Star3,Star4,No_of_Votes,Gross\r",
      "\r\n",
      "\"https://m.media-amazon.com/images/M/MV5BMDFkYTc0MGEtZmNhMC00ZDIzLWFmNTEtODM1ZmRlYWMwMWFmXkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_UX67_CR0,0,67,98_AL_.jpg\",The Shawshank Redemption,1994,A,142 min,Drama,9.3,\"Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.\",80,Frank Darabont,Tim Robbins,Morgan Freeman,Bob Gunton,William Sadler,2343110,28341469\r",
      "\r\n",
      "\"https://m.media-amazon.com/images/M/MV5BM2MyNjYxNmUtYTAwNi00MTYxLWJmNWYtYzZlODY3ZTk3OTFlXkEyXkFqcGdeQXVyNzkwMjQ5NzM@._V1_UY98_CR1,0,67,98_AL_.jpg\",The Godfather,1972,A,175 min,Crime,9.2,An organized crime dynasty's aging patriarch transfers control of his clandestine empire to his reluctant son.,100,Francis Ford Coppola,Marlon Brando,Al Pacino,James Caan,Diane Keaton,1620367,134966411\r",
      "\r\n",
      "\"https://m.media-amazon.com/images/M/MV5BMTMxNTMwODM0NF5BMl5BanBnXkFtZTcwODAyMTk2Mw@@._V1_UX67_CR0,0,67,98_AL_.jpg\",The Dark Knight,2008,UA,152 min,Action,9,\"When the menace known as the Joker wreaks havoc and chaos on the people of Gotham, Batman must accept one of the greatest psychological and physical tests of his ability to fight injustice.\",84,Christopher Nolan,Christian Bale,Heath Ledger,Aaron Eckhart,Michael Caine,2303232,534858444\r",
      "\r\n",
      "\"https://m.media-amazon.com/images/M/MV5BMWMwMGQzZTItY2JlNC00OWZiLWIyMDctNDk2ZDQ2YjRjMWQ0XkEyXkFqcGdeQXVyNzkwMjQ5NzM@._V1_UY98_CR1,0,67,98_AL_.jpg\",The Godfather: Part II,1974,A,202 min,Crime,9,\"The early life and career of Vito Corleone in 1920s New York City is portrayed, while his son, Michael, expands and tightens his grip on the family crime syndicate.\",90,Francis Ford Coppola,Al Pacino,Robert De Niro,Robert Duvall,Diane Keaton,1129952,57300000\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 data/imdb_top_1000.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333864f",
   "metadata": {},
   "source": [
    "Let's read our dataframe data and apply some parameters to it: \n",
    "- format() to specify the format of the file used;\n",
    "- option() clarify parameters, presence of header;\n",
    "- load() the path to the file to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca5b7aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read dataframe\n",
    "\n",
    "df = spark.read.format('csv').option('header', 'true').load('data/imdb_top_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a23a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+-----------+-------+------+-----------+--------------------+----------+--------------------+--------------+--------------+-------------+--------------+-----------+---------+\n",
      "|         Poster_Link|        Series_Title|Released_Year|Certificate|Runtime| Genre|IMDB_Rating|            Overview|Meta_score|            Director|         Star1|         Star2|        Star3|         Star4|No_of_Votes|    Gross|\n",
      "+--------------------+--------------------+-------------+-----------+-------+------+-----------+--------------------+----------+--------------------+--------------+--------------+-------------+--------------+-----------+---------+\n",
      "|https://m.media-a...|The Shawshank Red...|         1994|          A|142 min| Drama|        9.3|Two imprisoned me...|        80|      Frank Darabont|   Tim Robbins|Morgan Freeman|   Bob Gunton|William Sadler|    2343110| 28341469|\n",
      "|https://m.media-a...|       The Godfather|         1972|          A|175 min| Crime|        9.2|An organized crim...|       100|Francis Ford Coppola| Marlon Brando|     Al Pacino|   James Caan|  Diane Keaton|    1620367|134966411|\n",
      "|https://m.media-a...|     The Dark Knight|         2008|         UA|152 min|Action|          9|When the menace k...|        84|   Christopher Nolan|Christian Bale|  Heath Ledger|Aaron Eckhart| Michael Caine|    2303232|534858444|\n",
      "|https://m.media-a...|The Godfather: Pa...|         1974|          A|202 min| Crime|          9|The early life an...|        90|Francis Ford Coppola|     Al Pacino|Robert De Niro|Robert Duvall|  Diane Keaton|    1129952| 57300000|\n",
      "|https://m.media-a...|        12 Angry Men|         1957|          U| 96 min| Crime|          9|A jury holdout at...|        96|        Sidney Lumet|   Henry Fonda|   Lee J. Cobb|Martin Balsam|  John Fiedler|     689845|  4360000|\n",
      "+--------------------+--------------------+-------------+-----------+-------+------+-----------+--------------------+----------+--------------------+--------------+--------------+-------------+--------------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open df 5 row\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac443b",
   "metadata": {},
   "source": [
    "In case the table does not fit into the frame of the markup, you can test the display of the dataframe by adding the show method with the parameter vertical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9b67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " Poster_Link   | https://m.media-a... \n",
      " Series_Title  | The Shawshank Red... \n",
      " Released_Year | 1994                 \n",
      " Certificate   | A                    \n",
      " Runtime       | 142 min              \n",
      " Genre         | Drama                \n",
      " IMDB_Rating   | 9.3                  \n",
      " Overview      | Two imprisoned me... \n",
      " Meta_score    | 80                   \n",
      " Director      | Frank Darabont       \n",
      " Star1         | Tim Robbins          \n",
      " Star2         | Morgan Freeman       \n",
      " Star3         | Bob Gunton           \n",
      " Star4         | William Sadler       \n",
      " No_of_Votes   | 2343110              \n",
      " Gross         | 28341469             \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open df 1 row\n",
    "# use vertical params\n",
    "\n",
    "df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fbebb",
   "metadata": {},
   "source": [
    "Let's take a look slightly at our dataframe using the Spark API functions.\n",
    "\n",
    "Consider the first function SELECT. Just as in the SQL language, so in the Spark API, the function is used to create selections of certain columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29efc913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Series_Title: string, Released_Year: string, IMDB_Rating: string, Genre: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use select()\n",
    "\n",
    "df.select('Series_Title', 'Released_Year', 'IMDB_Rating', 'Genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d0c2a",
   "metadata": {},
   "source": [
    "The API does not give us the most useful information. In order to see the dataframe, we need to use the show() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43624360",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+------+\n",
      "|        Series_Title|Released_Year|IMDB_Rating| Genre|\n",
      "+--------------------+-------------+-----------+------+\n",
      "|The Shawshank Red...|         1994|        9.3| Drama|\n",
      "|       The Godfather|         1972|        9.2| Crime|\n",
      "|     The Dark Knight|         2008|          9|Action|\n",
      "|The Godfather: Pa...|         1974|          9| Crime|\n",
      "|        12 Angry Men|         1957|          9| Crime|\n",
      "+--------------------+-------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use select()\n",
    "## then use show()\n",
    "\n",
    "df.select(\n",
    "    'Series_Title', 'Released_Year', 'IMDB_Rating', 'Genre'\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf7a6c",
   "metadata": {},
   "source": [
    "Done! \n",
    "\n",
    "To further interact with the functions, we import the pyspark.sql.functions package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b6389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce79ebf",
   "metadata": {},
   "source": [
    "Using the functions, the access to the columns is as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aae3419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+------+\n",
      "|        Series_Title|Released_Year|IMDB_Rating| Genre|\n",
      "+--------------------+-------------+-----------+------+\n",
      "|The Shawshank Red...|         1994|        9.3| Drama|\n",
      "|       The Godfather|         1972|        9.2| Crime|\n",
      "|     The Dark Knight|         2008|          9|Action|\n",
      "|The Godfather: Pa...|         1974|          9| Crime|\n",
      "|        12 Angry Men|         1957|          9| Crime|\n",
      "+--------------------+-------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    F.col('Series_Title'), F.col('Released_Year'),\n",
    "    F.col('IMDB_Rating'), F.col('Genre'),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd22da",
   "metadata": {},
   "source": [
    "This is necessary for the convenience of using additional conditions or logical expressions for columns. \n",
    "\n",
    "Let's use the .filter() command to show how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68de6a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+-----+\n",
      "|        Series_Title|Released_Year|IMDB_Rating|Genre|\n",
      "+--------------------+-------------+-----------+-----+\n",
      "|The Shawshank Red...|         1994|        9.3|Drama|\n",
      "|          Fight Club|         1999|        8.8|Drama|\n",
      "|        Forrest Gump|         1994|        8.8|Drama|\n",
      "|One Flew Over the...|         1975|        8.7|Drama|\n",
      "|     Soorarai Pottru|         2020|        8.6|Drama|\n",
      "+--------------------+-------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use .filter()\n",
    "\n",
    "df\\\n",
    "    .filter('Genre = \"Drama\"')\\\n",
    "    .select(\n",
    "        F.col('Series_Title'), F.col('Released_Year'),\n",
    "        F.col('IMDB_Rating'), F.col('Genre'),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ce2be",
   "metadata": {},
   "source": [
    "We can use complex expressions in filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fdf6126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+-----+\n",
      "|        Series_Title|Released_Year|IMDB_Rating|Genre|\n",
      "+--------------------+-------------+-----------+-----+\n",
      "|                1917|         2019|        8.3|Drama|\n",
      "|Miracle in cell NO.7|         2019|        8.3|Drama|\n",
      "|Portrait de la je...|         2019|        8.1|Drama|\n",
      "|           Gully Boy|         2019|          8|Drama|\n",
      "|      Sound of Metal|         2019|        7.8|Drama|\n",
      "+--------------------+-------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use harder .filter()\n",
    "\n",
    "df\\\n",
    "    .filter('Genre = \"Drama\" and Released_Year = \"2019\"')\\\n",
    "    .select(\n",
    "        F.col('Series_Title'), F.col('Released_Year'),\n",
    "        F.col('IMDB_Rating'), F.col('Genre'),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82114c1c",
   "metadata": {},
   "source": [
    "Is 1917 really a drama? \n",
    "Although I am surprised, we go on. \n",
    "\n",
    "In order not to get confused by the complex filtering, you can apply the .filter() command twice. The filtering will be performed sequentially. Spark will first filter the source dataset by the first condition, then by the second condition, and then it will address the specified columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24814c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+-----+\n",
      "|        Series_Title|Released_Year|IMDB_Rating|Genre|\n",
      "+--------------------+-------------+-----------+-----+\n",
      "|                1917|         2019|        8.3|Drama|\n",
      "|Miracle in cell NO.7|         2019|        8.3|Drama|\n",
      "|Portrait de la je...|         2019|        8.1|Drama|\n",
      "|           Gully Boy|         2019|          8|Drama|\n",
      "|      Sound of Metal|         2019|        7.8|Drama|\n",
      "+--------------------+-------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use harder .filter()\n",
    "\n",
    "df\\\n",
    "    .filter('Genre = \"Drama\"')\\\n",
    "    .filter('Released_Year = \"2019\"')\\\n",
    "    .select(\n",
    "        F.col('Series_Title'), F.col('Released_Year'),\n",
    "        F.col('IMDB_Rating'), F.col('Genre'),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b36adfa",
   "metadata": {},
   "source": [
    "When F.col() is accessed, we can talk to expressions as Python objects to compare parameters externally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3efdb74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+-----+\n",
      "|        Series_Title|Released_Year|IMDB_Rating|Genre|\n",
      "+--------------------+-------------+-----------+-----+\n",
      "|                1917|         2019|        8.3|Drama|\n",
      "|Miracle in cell NO.7|         2019|        8.3|Drama|\n",
      "|Portrait de la je...|         2019|        8.1|Drama|\n",
      "|           Gully Boy|         2019|          8|Drama|\n",
      "|      Sound of Metal|         2019|        7.8|Drama|\n",
      "+--------------------+-------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill in the external variables\n",
    "\n",
    "genre = 'Drama'\n",
    "year = 2019\n",
    "\n",
    "# use .filter()\n",
    "\n",
    "df\\\n",
    "    .filter(F.col('Genre') == genre)\\\n",
    "    .filter(F.col('Released_Year') == year)\\\n",
    "    .select(\n",
    "        F.col('Series_Title'), F.col('Released_Year'),\n",
    "        F.col('IMDB_Rating'), F.col('Genre'),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba3994",
   "metadata": {},
   "source": [
    "Also, but the process involves the possibility of automation.\n",
    "\n",
    "Let's calculate the number of rows using the Spark functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f52662f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use .count()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07d518",
   "metadata": {},
   "source": [
    "Let's calculate the number of unique rows using the Spark functions. We will use the .distinct function as in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebfe86a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use .distinct()\n",
    "## then .count()\n",
    "\n",
    "df.select('Genre').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc04f4",
   "metadata": {},
   "source": [
    "14 different genres in dataframe! A big number for the film industry. \n",
    "\n",
    "Now let's examine the grouping and aggregation functions. Like count() and distinct(), Spark SQL uses the .groupBy() and .orderBy() operators. We will count the number of movies by genre in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ba7f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Genre: string, count: bigint]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use .groupBy()\n",
    "\n",
    "df.groupBy('Genre').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d81ebc",
   "metadata": {},
   "source": [
    "*DataFrame[Genre: string, count: bigint]* - That's not what we need, right? \n",
    "Spark returned us the dataframe data type, so we need to use the .show() operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4f7023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|    Genre|count|\n",
      "+---------+-----+\n",
      "|    Crime|  107|\n",
      "| Thriller|    1|\n",
      "|Adventure|   72|\n",
      "|    Drama|  289|\n",
      "|   Family|    2|\n",
      "|  Fantasy|    2|\n",
      "|  Mystery|   12|\n",
      "|Animation|   82|\n",
      "|Film-Noir|    3|\n",
      "|   Horror|   11|\n",
      "|  Western|    4|\n",
      "|Biography|   88|\n",
      "|   Comedy|  155|\n",
      "|   Action|  172|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use .groupBy()\n",
    "## then .show()\n",
    "\n",
    "df.groupBy('Genre').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47765fa",
   "metadata": {},
   "source": [
    "Let's see which genres are least present in the sample using the .groupBy() and .orderBy() operators together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b49393a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|    Genre|count|\n",
      "+---------+-----+\n",
      "| Thriller|    1|\n",
      "|   Family|    2|\n",
      "|  Fantasy|    2|\n",
      "|Film-Noir|    3|\n",
      "|  Western|    4|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use .groupBy()\n",
    "## then .orderBy()\n",
    "\n",
    "df.groupBy('Genre').count().orderBy('count').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b53e32",
   "metadata": {},
   "source": [
    "Let's make the top 5 by the number of movies in the genre. Мы будем использовать F.col() совместно с модификатором .desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a39f910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|    Genre|count|\n",
      "+---------+-----+\n",
      "|    Drama|  289|\n",
      "|   Action|  172|\n",
      "|   Comedy|  155|\n",
      "|    Crime|  107|\n",
      "|Biography|   88|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use .groupBy()\n",
    "## then .orderBy()\n",
    "\n",
    "df.groupBy('Genre').count().orderBy(F.col('count').desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b327a",
   "metadata": {},
   "source": [
    "The Drama. \n",
    "\n",
    "If we need to rename a column, we will use the .withColumnRenamed() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3525287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              Poster|\n",
      "+--------------------+\n",
      "|https://m.media-a...|\n",
      "|https://m.media-a...|\n",
      "|https://m.media-a...|\n",
      "|https://m.media-a...|\n",
      "|https://m.media-a...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use .withColumnRenamed()\n",
    "\n",
    "df.withColumnRenamed('Poster_Link', 'Poster').select('Poster').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db04491e",
   "metadata": {},
   "source": [
    "Simple. \n",
    "\n",
    "With the .withColumn() method you can create a new column. First, import the desired data type. Second, let's use the .regex_replace method to exclude the designation **min**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08589464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|        Series_Title|Runtime|\n",
      "+--------------------+-------+\n",
      "|The Shawshank Red...|    142|\n",
      "|       The Godfather|    175|\n",
      "|     The Dark Knight|    152|\n",
      "|The Godfather: Pa...|    202|\n",
      "|        12 Angry Men|     96|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "# use .withColumn()\n",
    "\n",
    "df.withColumn(\n",
    "    'Runtime', F.regexp_replace(F.col('Runtime'), ' min', '')\n",
    ").select('Series_Title', 'Runtime').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ee91a",
   "metadata": {},
   "source": [
    "Then use .cast() to change the type. For further communication it is necessary to save our dataframe into a new variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08c54292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .withColumn()\n",
    "## and .cast()\n",
    "\n",
    "df_filtered = df.withColumn(\n",
    "    'Runtime', F.col('Runtime').cast(IntegerType())\n",
    ").select('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2d3df",
   "metadata": {},
   "source": [
    "We use .cast() for the other lines in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee1f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .withColumn()\n",
    "## and .cast()\n",
    "\n",
    "df_filtered = df\\\n",
    "    .withColumn(\n",
    "        'Runtime', F.col('Runtime').cast(IntegerType()))\\\n",
    "    .withColumn(\n",
    "        'IMDB_Rating', F.col('IMDB_Rating').cast(FloatType()))\\\n",
    "    .withColumn(\n",
    "        'Meta_score', F.col('Meta_score').cast(IntegerType())\n",
    ").select('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d0d95",
   "metadata": {},
   "source": [
    "Let's see if we were able to create a new column. Let's use the .printSchema function to print a description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ae29dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Poster_Link: string (nullable = true)\n",
      " |-- Series_Title: string (nullable = true)\n",
      " |-- Released_Year: string (nullable = true)\n",
      " |-- Certificate: string (nullable = true)\n",
      " |-- Runtime: integer (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- IMDB_Rating: float (nullable = true)\n",
      " |-- Overview: string (nullable = true)\n",
      " |-- Meta_score: integer (nullable = true)\n",
      " |-- Director: string (nullable = true)\n",
      " |-- Star1: string (nullable = true)\n",
      " |-- Star2: string (nullable = true)\n",
      " |-- Star3: string (nullable = true)\n",
      " |-- Star4: string (nullable = true)\n",
      " |-- No_of_Votes: string (nullable = true)\n",
      " |-- Gross: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804bcf8",
   "metadata": {},
   "source": [
    "We can also use the .describe method. It can be used to describe the columns in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bb97bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+------------------+\n",
      "|summary|Runtime|       IMDB_Rating|        Meta_score|\n",
      "+-------+-------+------------------+------------------+\n",
      "|  count|      0|              1000|               830|\n",
      "|   mean|   null| 7.949300034046173| 78.03734939759036|\n",
      "| stddev|   null|0.2754912482773137|12.363212589581746|\n",
      "|    min|   null|               7.6|                28|\n",
      "|    max|   null|               9.3|               100|\n",
      "+-------+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use .describe\n",
    "\n",
    "df_filtered.select('Runtime', 'IMDB_Rating', 'Meta_score').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fc4af",
   "metadata": {},
   "source": [
    "Mean of IMBD_Rating is 7.94. Mean of Meta_score is 78.04. That's a Bingo - said Christoph Waltz in \"Inglourious Basterds\"! \n",
    "\n",
    "Let's re-save our dataframe to csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99f744b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use write\n",
    "\n",
    "df_filtered.write.mode('overwrite')\\\n",
    "    .format('csv').save('results_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8546d",
   "metadata": {},
   "source": [
    "Lets start the basic ETL-pipeline.\n",
    "\n",
    "## Second stage.\n",
    "\n",
    "At this stage we will try to make a small ETL-pipeline to understand how Spark and data interact. We will use dataframes, which would not be difficult to analyze with elements of the Pandas library, but we will do it with Spark in order to examine the different methods and functions used by the engine. \n",
    "\n",
    "We need to calculate for each year (Released_Year):\n",
    "\n",
    "- number of movies;\n",
    "- average IMDB rating;\n",
    "- minimum IMDB rating;\n",
    "- maximum IMDB rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0595917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d169f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data func\n",
    "\n",
    "def extract_data(spark: SparkSession) -> DataFrame:\n",
    "    path = 'data/imdb_top_1000.csv'\n",
    "    return spark.read.option(\"header\", \"true\").csv(path)\n",
    "\n",
    "# transform data func\n",
    "\n",
    "def transform_data(df: DataFrame) -> DataFrame:\n",
    "    output = (\n",
    "        df\n",
    "        .groupBy(\"Released_Year\")\n",
    "        .agg(\n",
    "            F.count(\"Released_Year\").alias(\"count_movies\"),\n",
    "            F.round(F.avg(F.col(\"IMDB_Rating\").cast(FloatType()))).alias(\"avg_imdb_rating\"),\n",
    "            F.min(F.col(\"IMDB_Rating\").cast(FloatType())).alias(\"min_imdb_rating\"),\n",
    "            F.max(F.col(\"IMDB_Rating\").cast(FloatType())).alias(\"max_imdb_rating\"),\n",
    "        )\n",
    "        .orderBy(F.col(\"count_movies\").desc())\n",
    "    )\n",
    "    return output\n",
    "\n",
    "# load data func\n",
    "\n",
    "def save_data(df: DataFrame) -> None:\n",
    "    df.write.mode(\"overwrite\").format(\"csv\").option(\"header\", \"true\").save(\"output.csv\")\n",
    "\n",
    "# ETL-pipeline func\n",
    "\n",
    "def main():\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    df = extract_data(spark)\n",
    "    output = transform_data(df)\n",
    "    save_data(output)\n",
    "    #spark.stop()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed167026",
   "metadata": {},
   "source": [
    "Simply! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "733144bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+---------------+---------------+---------------+\n",
      "|Released_Year|count_movies|avg_imdb_rating|min_imdb_rating|max_imdb_rating|\n",
      "+-------------+------------+---------------+---------------+---------------+\n",
      "|         2014|          32|            8.0|            7.6|            8.6|\n",
      "|         2004|          31|            8.0|            7.6|            8.3|\n",
      "|         2009|          29|            8.0|            7.6|            8.4|\n",
      "|         2016|          28|            8.0|            7.6|            8.4|\n",
      "|         2013|          28|            8.0|            7.6|            8.3|\n",
      "|         2001|          27|            8.0|            7.6|            8.8|\n",
      "|         2006|          26|            8.0|            7.6|            8.5|\n",
      "|         2007|          26|            8.0|            7.6|            8.4|\n",
      "|         2015|          25|            8.0|            7.6|            8.2|\n",
      "|         2012|          24|            8.0|            7.6|            8.4|\n",
      "|         2019|          23|            8.0|            7.6|            8.6|\n",
      "|         1993|          23|            8.0|            7.6|            8.9|\n",
      "|         2010|          23|            8.0|            7.6|            8.8|\n",
      "|         2017|          22|            8.0|            7.6|            8.4|\n",
      "|         2003|          22|            8.0|            7.6|            8.9|\n",
      "|         2008|          21|            8.0|            7.6|            9.0|\n",
      "|         2000|          19|            8.0|            7.6|            8.5|\n",
      "|         2002|          19|            8.0|            7.6|            8.7|\n",
      "|         2018|          19|            8.0|            7.6|            8.4|\n",
      "|         1995|          19|            8.0|            7.6|            8.6|\n",
      "+-------------+------------+---------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option(\"header\", \"true\")\\\n",
    "    .csv(\"output.csv/part-00000-ecc2b750-1a83-4f76-943b-924fa7d498e1-c000.csv\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3cae4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
